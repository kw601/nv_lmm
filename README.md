# LLM 기반 한영 번역 모델 개선 연구

## 📖 연구 개요

AI 번역 기술은 빠른 속도와 높은 정확성을 제공하지만, 문화적 배경이나 문맥을 반영한 **의역(意譯)**에는 한계를 보입니다.  
본 연구에서는 **LLM 기반 모델을 활용하여 보다 자연스러운 한영 번역을 구현**하고, 기존 번역 모델의 성능을 비교 분석하였습니다.

## 🎯 연구 목표

- **문맥을 반영한 자연스러운 번역 제공**
- 기존 기계 번역 모델이 직역에 의존하는 문제 해결
- LLM을 활용하여 의역이 가능한 번역 성능 향상

## 🛠 사용 데이터셋

- **한국어-영어 번역 병렬 말뭉치 (AI Hub 제공)**
  - 약 50만 개의 라벨링된 한영 번역 문장 데이터
  - 상황별 신조어, 관용적 표현 등을 포함
- **PAWS-X 데이터셋 (Google 제공)**
  - 다국어 번역을 위한 패러프레이징(Paraphrasing) 데이터셋
  - 문맥과 단어 순서의 중요성을 학습하기 위한 구성

## 🏗️ 사용 모델

본 연구에서는 **4가지 기계 번역 모델을 비교 평가**하였습니다.

1. **KE-T5-base**: 한국어 데이터 중심 T5 기반 번역 모델
2. **KoBART**: 한국어 번역을 위해 학습된 BART 기반 모델
3. **NLLB-200**: Meta AI에서 개발한 다국어 번역 모델
4. **Long-KE-T5**: 입력 길이를 확장하여 문맥을 더 많이 고려할 수 있도록 개선된 KE-T5

## 🧑‍💻 본인 역할

- **데이터 전처리 및 병렬 코퍼스 구축**
  - 문맥 유지 및 의미 보존을 위한 데이터 정제 및 필터링 적용
- **모델 학습 및 최적화**
  - KE-T5-base 모델 및 Long-KE-T5 모델을 파인튜닝하여 번역 성능 향상
  - 하이퍼파라미터 조정 및 학습률 최적화 진행
- **모델 성능 평가 및 분석**
  - BLEU, BERTScore 등의 평가 지표 활용
  - 기존 모델 대비 성능 차이를 분석하고 최적의 모델 선정

## 🔍 연구 결과

- **BERTScore 평가 결과**
  - KE-T5-base 모델 파인튜닝 결과 **0.73 → 0.77**
  - Long-KE-T5 모델이 **0.81로 가장 높은 성능을 기록**
- **의역이 강화된 번역 생성**
  - 기존 모델은 직역에 의존했으나, 최적화된 모델은 문맥을 반영한 번역을 생성

## 📌 연구 의의 및 향후 발전 방향

- LLM 기반 번역 모델이 **기존 번역기의 직역 한계를 극복하는 데 기여 가능**
- 향후 연구에서는 **사용자 피드백을 반영하는 인터랙티브 번역 시스템 개발 계획**
